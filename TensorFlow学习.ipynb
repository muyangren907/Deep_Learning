{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow学习.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muyangren907/Machine_Learning/blob/master/TensorFlow%E5%AD%A6%E4%B9%A0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLNqDimrQvf8",
        "colab_type": "text"
      },
      "source": [
        "# 第一个TensorFlow程序（Hello World）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWgPwrtFQ0ZY",
        "colab_type": "code",
        "outputId": "a7df86bc-a4a8-4e3a-c3c0-a9237366b068",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "message = tf.constant(\"Hello World\")\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(message).decode())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObEynjaNRvRz",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow程序结构"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWN595MmR80M",
        "colab_type": "code",
        "outputId": "978c44c7-8d8d-40e7-eb73-804482846bb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "v_1 = tf.constant([1,2,3,4])\n",
        "v_2 = tf.constant([2,1,5,3])\n",
        "v_add = tf.add(v_1,v_2) # You can also write v_1 + v_2\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(v_add))\n",
        "\n",
        "# You can also write\n",
        "# sess = tf.Session()\n",
        "# print(sess.run(v_add))\n",
        "# sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 3 8 7]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdTUcMs7T6lG",
        "colab_type": "text"
      },
      "source": [
        "如果你正在使用 Jupyter Notebook 或者 Python shell 进行编程，使用 tf.InteractiveSession 将比 tf.Session 更方便。InteractiveSession 使自己成为默认会话，因此你可以使用 eval() 直接调用运行张量对象而不用显式调用会话。下面给出一个例子："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUF8Ge-lT8I5",
        "colab_type": "code",
        "outputId": "5387e1cf-ea0d-4d9b-9b70-533f7272053d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "sess = tf.InteractiveSession()\n",
        "v_1 = tf.constant([1,2,3,4])\n",
        "v_2 = tf.constant([2,1,5,3])\n",
        "v_add = tf.add(v_1,v_2)\n",
        "print(v_add.eval())\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 3 8 7]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtEWNJjFUctU",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow常量、变量和占位符"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9xHZftJZnMF",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow 常量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBiXgWp1UeF7",
        "colab_type": "code",
        "outputId": "e8c1d31b-c9dd-4ebc-b02b-9f5ce90ae795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        }
      },
      "source": [
        "# 声明一个标量常量：\n",
        "t_1 = tf.constant(4)\n",
        "with tf.Session() as sess:\n",
        "  print(sess.run(t_1))\n",
        "\n",
        "# 一个形如 [1，3] 的常量向量可以用如下代码声明：\n",
        "t_2 = tf.constant([4,3,2])\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(t_2))\n",
        "\n",
        "# 要创建一个所有元素为零的张量，可以使用 tf.zeros() 函数。这个语句可以创建\n",
        "# 一个形如 [M，N] 的零元素矩阵，数据类型（dtype）可以是 int32、float32 等：\n",
        "# tf.zeros([M,N],tf.dtype)\n",
        "zero_t = tf.zeros([4,3],tf.int32)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(zero_t))\n",
        "\n",
        "# 还可以创建与现有 Numpy 数组或张量常量具有相同形状的张量常量，如下所示：\n",
        "ones_t = tf.ones_like(zero_t)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(ones_t))\n",
        "\n",
        "# 在一定范围内生成一个从初值到终值等差排布的序列：\n",
        "# tf.linspace(start,stop,num)\n",
        "# start stop :  fliat\n",
        "range_t = tf.linspace(1.0,10.0,10)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(range_t))\n",
        "\n",
        "# 从开始（默认值=0）生成一个数字序列，增量为 delta（默认值=1），\n",
        "# 直到终值（但不包括终值）：\n",
        "# tf.range(start,limit,delta)\n",
        "range_t = tf.range(1.0,90.0,10)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(range_t))\n",
        "\n",
        "# 使用以下语句创建一个具有一定均值（默认值=0.0）和标准差（默认值=1.0）、\n",
        "# 形状为 [M，N] 的正态分布随机数组：\n",
        "t_random = tf.random_normal([2,3],2.0,stddev=4,seed=12)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(t_random))\n",
        "\n",
        "# 创建一个具有一定均值（默认值=0.0）和标准差（默认值=1.0）、形状为 [M，N] 的\n",
        "# 截尾正态分布随机数组：\n",
        "t_random = tf.truncated_normal([1,5],stddev=2,seed=12)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(t_random))\n",
        "\n",
        "# 要在种子的 [minval（default=0），maxval] 范围内创建形状为 [M，N] 的给定\n",
        "# 伽马分布随机数组，请执行如下语句\n",
        "t_random2 = tf.random_uniform([5,6],maxval=4,seed=12)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(t_random2))\n",
        "\n",
        "# 要将给定的张量随机裁剪为指定的大小，使用以下语句：\n",
        "# t_random 是一个已经定义好的张量。这将导致随机从张量 t_random 中裁剪出一个\n",
        "# 大小为 [2，5] 的张量。\n",
        "tf_random_crop = tf.random_crop(t_random2,[4,3],seed=12)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(tf_random_crop))\n",
        "\n",
        "# 很多时候需要以随机的顺序来呈现训练样本，可以使用 tf.random_shuffle() 来沿着\n",
        "# 它的第一维随机排列张量。如果 t_random 是想要重新排序的张量，使用下面的代码：\n",
        "\n",
        "t_random_shuffle = tf.random_shuffle(tf_random_crop)\n",
        "with tf.Session() as sess:\n",
        "  print('\\n',sess.run(t_random_shuffle))\n",
        "\n",
        "# 随机生成的张量受初始种子值的影响。要在多次运行或会话中获得相同的随机数，应该\n",
        "# 将种子设置为一个常数值。当使用大量的随机张量时，可以使用 tf.set_random_seed() \n",
        "# 来为所有随机产生的张量设置种子。以下命令将所有会话的随机张量的种子设置为 54：\n",
        "tf.set_random_seed(54)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n",
            "\n",
            " [4 3 2]\n",
            "\n",
            " [[0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n",
            "\n",
            " [[1 1 1]\n",
            " [1 1 1]\n",
            " [1 1 1]\n",
            " [1 1 1]]\n",
            "\n",
            " [ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n",
            "\n",
            " [ 1. 11. 21. 31. 41. 51. 61. 71. 81.]\n",
            "\n",
            " [[-5.3299294  6.88009    6.4126735]\n",
            " [ 8.594671  -6.604518  10.532751 ]]\n",
            "\n",
            " [[-3.6649647  2.440045   2.2063367  3.2973356  0.3111803]]\n",
            "\n",
            " [[0.35454178 3.3739414  0.5591998  0.37541723 0.04065514 3.497334  ]\n",
            " [1.4685888  2.7888331  1.9283228  0.3767681  2.2410283  2.9267573 ]\n",
            " [1.4547715  2.1593485  1.6037321  3.50946    2.061996   1.9372883 ]\n",
            " [0.7182331  1.9995828  3.5743747  3.2437034  0.2526312  0.8461442 ]\n",
            " [0.4002676  3.8541117  0.3089533  0.34722805 1.4419994  2.4083471 ]]\n",
            "\n",
            " [[3.3739414  0.5591998  0.37541723]\n",
            " [2.7888331  1.9283228  0.3767681 ]\n",
            " [2.1593485  1.6037321  3.50946   ]\n",
            " [1.9995828  3.5743747  3.2437034 ]]\n",
            "\n",
            " [[2.7888331  1.9283228  0.3767681 ]\n",
            " [1.9995828  3.5743747  3.2437034 ]\n",
            " [2.1593485  1.6037321  3.50946   ]\n",
            " [3.3739414  0.5591998  0.37541723]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LaJlCLEpdhnn",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow 变量"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUBrJhQgdj4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 它们通过使用变量类来创建。变量的定义还包括应该初始化的常量/随机值。\n",
        "# 下面的代码中创建了两个不同的张量变量 t_a 和 t_b。\n",
        "# 两者将被初始化为形状为 [20，30] 的随机均匀分布，最小值=0，最大值=10：\n",
        "rand_t = tf.random_uniform([20,30],0,10,seed=0)\n",
        "t_a = tf.Variable(rand_t)\n",
        "t_b = tf.Variable(rand_t)\n",
        "# 注意：变量通常在神经网络中表示权重和偏置。\n",
        "\n",
        "# 下面的代码中定义了两个变量的权重和偏置。\n",
        "# 权重变量使用正态分布随机初始化，均值为 0，标准差为 2，\n",
        "# 权重大小为 100×100。偏置由 100 个元素组成，每个元素初始化为 0。\n",
        "# 在这里也使用了可选参数名以给计算图中定义的变量命名：\n",
        "weights = tf.Variable(tf.random_normal([100,100],stddev=2))\n",
        "bias = tf.Variable(tf.zeros(100),name='biases')\n",
        "\n",
        "# 在前面的例子中，都是利用一些常量来初始化变量，也可以指定一个变量来初始化另一个变量。\n",
        "# 下面的语句将利用前面定义的权重来初始化 weight2：\n",
        "weights2 = tf.Variable(weights.initialized_value(),name='w2')\n",
        "\n",
        "# 变量的定义将指定变量如何被初始化，但是必须显式初始化所有的声明变量。\n",
        "# 在计算图的定义中通过声明初始化操作对象来实现：\n",
        "initial_op = tf.global_variables_initializer()\n",
        "\n",
        "# 每个变量也可以在运行图中单独使用 tf.Variable.initializer 来初始化：\n",
        "bias = tf.Variable(tf.zeros([100,100]))\n",
        "with tf.Session() as sess:\n",
        "  sess.run(bias.initializer)\n",
        "\n",
        "# 保存变量：使用 Saver 类来保存变量，定义一个 Saver 操作对象：\n",
        "saver = tf.train.Saver() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NPEbplLhWhA",
        "colab_type": "text"
      },
      "source": [
        "## TensorFlow 占位符"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1FKGh8ahcI8",
        "colab_type": "code",
        "outputId": "259308f9-79db-4c8f-ab7d-1f36e0e7c41c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "# 介绍完常量和变量之后，我们来讲解最重要的元素——占位符，\n",
        "# 它们用于将数据提供给计算图。可以使用以下方法定义一个占位符：\n",
        "# tf.placeholder(dtype,shape=None,name=None)\n",
        "# dtype 定占位符的数据类型，并且必须在声明占位符时指定。\n",
        "# 在这里，为 x 定义一个占位符并计算 y=2*x，使用 feed_dict 输入一个随机的 4×5 矩阵：\n",
        "x = tf.placeholder(tf.float32)\n",
        "y = 2 * x\n",
        "data = tf.random_uniform([4,5],10)\n",
        "with tf.Session() as sess:\n",
        "  x_data = sess.run(data)\n",
        "  y_ = sess.run(y,feed_dict={x:x_data})\n",
        "print(x_data)\n",
        "print(y_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[3.1778164 8.709591  7.535771  5.544607  4.6875687]\n",
            " [6.2226806 5.981759  7.0217867 4.8371143 5.2493024]\n",
            " [3.974957  3.2180357 5.5360594 7.096443  1.7906361]\n",
            " [6.8016834 4.996413  8.032926  5.7051115 3.8984604]]\n",
            "[[ 6.355633  17.419182  15.071542  11.089214   9.375137 ]\n",
            " [12.445361  11.963518  14.043573   9.674229  10.498605 ]\n",
            " [ 7.949914   6.4360714 11.072119  14.192886   3.5812721]\n",
            " [13.603367   9.992826  16.065851  11.410223   7.796921 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsM7ZdN_j41X",
        "colab_type": "text"
      },
      "source": [
        "## 注意事项"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ag_sz66Kj72A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 很多时候需要大规模的常量张量对象；在这种情况下，为了优化内存，\n",
        "# 最好将它们声明为一个可训练标志设置为 False 的变量：\n",
        "t_large = tf.Varible(large_array,trainable = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9njdnfEZkOJ5",
        "colab_type": "text"
      },
      "source": [
        "TensorFlow 被设计成与 Numpy 配合运行，因此所有的TensorFlow 数据类型都是基于 Numpy 的。使用tf.convert_to_tensor() 可以将给定的值转换为张量类型，并将其与 TensorFlow 函数和运算符一起使用。该函数接受 Numpy 数组、Python 列表和 Python 标量，并允许与张量对象互操作。\n",
        "\n",
        "![TensorFlow 支持的常见的数据类型](http://c.biancheng.net/uploads/allimg/190107/2-1Z10G4153M25.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0WNoNXZkz81",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow矩阵基本操作及其实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH-lFmrmk16s",
        "colab_type": "code",
        "outputId": "15712679-da58-4006-9acc-b89ee1682254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# 矩阵运算，例如执行乘法、加法和减法，是任何神经网络中信号传播的重要操作。通常在计算中需要随机矩阵、零矩阵、一矩阵或者单位矩阵。\n",
        "\n",
        "import tensorflow as tf\n",
        "sess = tf.InteractiveSession()\n",
        "I_matrix = tf.eye(5)\n",
        "print(I_matrix.eval())\n",
        "\n",
        "X = tf.Variable(tf.eye(6))\n",
        "X.initializer.run()\n",
        "print('\\n',X.eval())\n",
        "\n",
        "A = tf.Variable(tf.random_normal([3,6]))\n",
        "A.initializer.run()\n",
        "print('\\n',A.eval())\n",
        "\n",
        "product = tf.matmul(A,X)\n",
        "print('\\n',product.eval())\n",
        "\n",
        "b = tf.Variable(tf.random_uniform([3,6],0,2,dtype=tf.int32))\n",
        "b.initializer.run()\n",
        "print(b.eval())\n",
        "b_new = tf.cast(b,dtype=tf.float32)\n",
        "# Cast to float32 data type\n",
        "\n",
        "t_sum = tf.add(product,b_new)\n",
        "t_sub = product - b_new\n",
        "print('A * X + b = ',t_sum.eval())\n",
        "print('A * X - b = ',t_sub.eval())\n",
        "\n",
        "# 一些其他有用的矩阵操作，如按元素相乘、乘以一个标量、按元素相除、按元素余数相除等，可以执行如下语句：\n",
        "a = tf.Variable(tf.random_normal([4,5],stddev=2))\n",
        "b = tf.Variable(tf.random_normal([4,5],stddev=2))\n",
        "\n",
        "# 元素相乘\n",
        "A = a * b\n",
        "\n",
        "# 乘以一个标量\n",
        "B = tf.scalar_mul(2,A)\n",
        "\n",
        "# 按元素相除\n",
        "C = tf.div(a,b)\n",
        "\n",
        "# 按元素余数相除\n",
        "D = tf.mod(a,b)\n",
        "\n",
        "init_op = tf.global_variables_initializer()\n",
        "with tf.Session() as sess:\n",
        "  sess.run(init_op)\n",
        "  _a,_b,_A,_B,_C,_D = sess.run([a,b,A,B,C,D])\n",
        "\n",
        "print(_a)\n",
        "print(_b)\n",
        "print(_A)\n",
        "print(_B)\n",
        "print(_C)\n",
        "print(_D)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]]\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 1.]]\n",
            "\n",
            " [[-0.01338118 -1.1967833   0.9200098   1.2324066  -0.23509818 -0.23711362]\n",
            " [-1.7499586  -1.3421029   1.3887165   1.1838319  -1.3706229  -0.58759654]\n",
            " [ 0.92627     0.16264272 -1.8010796   1.8260559  -1.1232027   1.1859559 ]]\n",
            "\n",
            " [[-0.01338118 -1.1967833   0.9200098   1.2324066  -0.23509818 -0.23711362]\n",
            " [-1.7499586  -1.3421029   1.3887165   1.1838319  -1.3706229  -0.58759654]\n",
            " [ 0.92627     0.16264272 -1.8010796   1.8260559  -1.1232027   1.1859559 ]]\n",
            "[[0 0 1 1 0 0]\n",
            " [1 0 0 0 1 1]\n",
            " [1 0 1 0 1 1]]\n",
            "A * X + b =  [[-0.01338118 -1.1967833   1.9200099   2.2324066  -0.23509818 -0.23711362]\n",
            " [-0.74995863 -1.3421029   1.3887165   1.1838319  -0.37062287  0.41240346]\n",
            " [ 1.92627     0.16264272 -0.80107963  1.8260559  -0.12320268  2.185956  ]]\n",
            "A * X - b =  [[-0.01338118 -1.1967833  -0.07999021  0.23240662 -0.23509818 -0.23711362]\n",
            " [-2.7499585  -1.3421029   1.3887165   1.1838319  -2.3706229  -1.5875965 ]\n",
            " [-0.07372999  0.16264272 -2.8010798   1.8260559  -2.1232028   0.18595588]]\n",
            "[[ 1.4883469   2.9326708  -1.9117436  -0.48875716 -0.98246807]\n",
            " [ 1.2702105   0.6525896   3.1596463  -0.6524825   1.6857425 ]\n",
            " [-3.0995896   2.8947334  -3.7589622   2.2864566  -1.5470706 ]\n",
            " [ 1.9935956   2.3579206  -0.1704063   2.1414492   1.9537636 ]]\n",
            "[[ 2.4563606  -0.8949759   1.8841631  -3.0723398   1.7418374 ]\n",
            " [-1.2833225  -2.2432864   0.09532218  0.66952914  0.5316339 ]\n",
            " [ 1.0128986  -1.6447791  -3.908807   -1.7944789   4.2198453 ]\n",
            " [-0.20173477 -0.91249925 -0.6567714  -0.30836904  1.6516482 ]]\n",
            "[[ 3.6559167  -2.6246698  -3.602037    1.501628   -1.7112997 ]\n",
            " [-1.6300896  -1.4639454   0.30118436 -0.43685606  0.89619786]\n",
            " [-3.1395698  -4.761197   14.693058   -4.1029983  -6.5283985 ]\n",
            " [-0.40217754 -2.1516008   0.11191799 -0.66035664  3.2269301 ]]\n",
            "[[  7.3118334   -5.2493396   -7.204074     3.003256    -3.4225993 ]\n",
            " [ -3.2601793   -2.9278908    0.6023687   -0.8737121    1.7923957 ]\n",
            " [ -6.2791395   -9.522394    29.386116    -8.2059965  -13.056797  ]\n",
            " [ -0.8043551   -4.3032017    0.22383597  -1.3207133    6.4538603 ]]\n",
            "[[ 0.6059155  -3.2768154  -1.0146381   0.15908304 -0.5640412 ]\n",
            " [-0.9897828  -0.29090786 33.147022   -0.9745394   3.1708708 ]\n",
            " [-3.0601184  -1.7599527   0.9616648  -1.2741618  -0.36661786]\n",
            " [-9.882261   -2.5840247   0.2594606  -6.9444366   1.1829176 ]]\n",
            "[[ 1.4883469  -0.6472328   1.8565826  -0.48875716  0.7593693 ]\n",
            " [-0.01311195 -1.5906968   0.01401444  0.01704663  0.09084076]\n",
            " [ 0.9520047  -0.39482474 -3.7589622  -1.3025012   2.6727748 ]\n",
            " [-0.02375206 -0.3795771  -0.1704063  -0.01713407  0.30211544]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDVjkeUzrkUy",
        "colab_type": "text"
      },
      "source": [
        "## 注意事项"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UOm7UsUsC02",
        "colab_type": "text"
      },
      "source": [
        "所有加法、减、除、乘（按元素相乘）、取余等矩阵的算术运算都要求两个张量矩阵是相同的数据类型，否则就会产生错误。可以使用 tf.cast() 将张量从一种数据类型转换为另一种数据类型。\n",
        "\n",
        "\n",
        "如果在整数张量之间进行除法，最好使用 tf.truediv(a，b)，因为它首先将整数张量转换为浮点类，然后再执行按位相除。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXjEzpDVunPR",
        "colab_type": "text"
      },
      "source": [
        "# TensorFlow TensorBoard可视化数据流图\n",
        "\n",
        "TensorFlow 使用 TensorBoard 来提供计算图形的图形图像。这使得理解、调试和优化复杂的神经网络程序变得很方便。TensorBoard 也可以提供有关网络执行的量化指标。它读取 TensorFlow 事件文件，其中包含运行 TensorFlow 会话期间生成的摘要数据。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7MB28EYuy1M",
        "colab_type": "text"
      },
      "source": [
        "使用 TensorBoard 的第一步是确定想要的 OP 摘要。以 DNN 为例，通常需要知道损失项（目标函数）如何随时间变化。在自适应学习率的优化中，学习率本身会随时间变化。可以在 tf.summary.scalar OP 的帮助下得到需要的术语摘要。假设损失变量定义了误差项，我们想知道它是如何随时间变化的："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q1Bjnm8upAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf...\n",
        "tf.summary.scalar('loss',loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM_LgaIfvMCL",
        "colab_type": "text"
      },
      "source": [
        "还可以使用 tf.summary.histogram 可视化梯度、权重或特定层的输出分布："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IvluPLdvM6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "output_tensor = tf.matmul(input_tensor,weights) + biases\n",
        "tf.summary.histogram('output',output_tensor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7FhDP2XvhcN",
        "colab_type": "text"
      },
      "source": [
        "摘要将在会话操作中生成。可以在计算图中定义 tf.merge_all_summaries OP 来通过一步操作得到摘要，而不需要单独执行每个摘要操作。\n",
        "\n",
        "生成的摘要需要用事件文件写入："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5df-OARDviXm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "writer = tf.summary.FileWriter('summary_dir',sess.graph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzoDB7Xav6ES",
        "colab_type": "text"
      },
      "source": [
        "这会将所有摘要和图形写入 summary_dir 目录中。现在，为了可视化摘要，需要从命令行中调用 TensorBoard："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aVdRazxv6qo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensorboard --logdir=summary_dir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGPYS9m-wIDW",
        "colab_type": "text"
      },
      "source": [
        "接下来，打开浏览器并输入地址 http://localhost:6006/（或运行 TensorBoard 命令后收到的链接）。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeQLy05VwLwe",
        "colab_type": "text"
      },
      "source": [
        "## Colab中使用TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQvvizOOwRkc",
        "colab_type": "code",
        "outputId": "5ec8510f-20dd-442f-fb3c-699cdd6ca893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "!pip install tensorboardcolab\n",
        "from tensorboardcolab import TensorBoardColab\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n",
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://9c244702.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqgmofkO1mFH",
        "colab_type": "code",
        "outputId": "89ba962e-860e-4449-cdbe-eac13baf62d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        }
      },
      "source": [
        "!pip install -q tf-nightly-2.0-preview\n",
        "from tensorflow import summary\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs/tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "ERROR: Failed to launch TensorBoard (exited with 1).\n",
              "Contents of stderr:\n",
              "Traceback (most recent call last):\n",
              "  File \"/usr/local/bin/tensorboard\", line 8, in <module>\n",
              "    sys.exit(run_main())\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/main.py\", line 59, in run_main\n",
              "    default.get_plugins() + default.get_dynamic_plugins(),\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/default.py\", line 115, in get_dynamic_plugins\n",
              "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/tensorboard/default.py\", line 115, in <listcomp>\n",
              "    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 2442, in load\n",
              "    self.require(*args, **kwargs)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 2465, in require\n",
              "    items = working_set.resolve(reqs, env, installer, extras=self.extras)\n",
              "  File \"/usr/local/lib/python3.6/dist-packages/pkg_resources/__init__.py\", line 791, in resolve\n",
              "    raise VersionConflict(dist, req).with_context(dependent_req)\n",
              "pkg_resources.VersionConflict: (grpcio 1.15.0 (/usr/local/lib/python3.6/dist-packages), Requirement.parse('grpcio>=1.24.3'))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI5DMOtq1bP0",
        "colab_type": "code",
        "outputId": "a7784bcc-2961-4e7c-c520-5b4a7295e327",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "source": [
        "\n",
        "\n",
        "current_time = str(datetime.datetime.now().timestamp())\n",
        "train_log_dir = 'logs/tensorboard/train/' + current_time\n",
        "test_log_dir = 'logs/tensorboard/test/' + current_time\n",
        "train_summary_writer = summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 95.2MB 113kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 63.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 12.5MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tb-nightly 2.1.0a20191206 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-663a31eb046e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install -q tf-nightly-2.0-preview'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'load_ext tensorboard.notebook'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcurrent_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_log_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'logs/tensorboard/train/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2158\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2160\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-63>\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/extension.py\u001b[0m in \u001b[0;36mload_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodule_str\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUsageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Missing module name.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextension_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'already loaded'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36mload_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0m__import__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/extensions.py\u001b[0m in \u001b[0;36m_call_load_ipython_extension\u001b[0;34m(self, mod)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_load_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'load_ipython_extension'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_ipython_extension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorboard/notebook.py\u001b[0m in \u001b[0;36mload_ipython_extension\u001b[0;34m(ipython)\u001b[0m\n\u001b[1;32m     87\u001b[0m   \"\"\"\n\u001b[1;32m     88\u001b[0m   raise RuntimeError(\n\u001b[0;32m---> 89\u001b[0;31m       \u001b[0;34m\"Use '%load_ext tensorboard' instead of '%load_ext tensorboard.notebook'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m   )\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Use '%load_ext tensorboard' instead of '%load_ext tensorboard.notebook'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwxJpZu3wlxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        " \n",
        "# 载入数据集\n",
        "mnist = input_data.read_data_sets(\"MNIST_data\", one_hot=True)\n",
        " \n",
        "# 批次的大小\n",
        "batch_size = 50\n",
        " \n",
        "# 计算一共有多少批次\n",
        "n_batch = mnist.train.num_examples // batch_size\n",
        " \n",
        "# 输入命名空间\n",
        "with tf.name_scope(\"input\"):\n",
        "    # 定义两个placeholder\n",
        "    x = tf.placeholder(tf.float32, [None, 28 * 28])\n",
        "    y = tf.placeholder(tf.float32, [None, 10])\n",
        " \n",
        "with tf.name_scope(\"layer\"):\n",
        "    # 创建一个简单的神经网络\n",
        "    with tf.name_scope(\"weight\"):\n",
        "        W = tf.Variable(tf.zeros([784, 10]))\n",
        "    with tf.name_scope(\"biases\"):\n",
        "        b = tf.Variable(tf.zeros([10]))\n",
        "    with tf.name_scope(\"wx_plus_b\"):\n",
        "        wx_plus_b = tf.matmul(x, W) + b\n",
        "    with tf.name_scope(\"softmax\"):\n",
        "        prediction = tf.nn.softmax(wx_plus_b)\n",
        " \n",
        "with tf.name_scope(\"loss\"):\n",
        "    # 二次代价函数\n",
        "    loss = tf.reduce_mean(tf.square(y - prediction))\n",
        " \n",
        "with tf.name_scope(\"train\"):\n",
        "    # 使用梯度下降法\n",
        "    train_step = tf.train.GradientDescentOptimizer(0.2).minimize(loss)\n",
        " \n",
        " \n",
        "# 初始化变量\n",
        "init = tf.global_variables_initializer()\n",
        " \n",
        "with tf.name_scope(\"accuracy\"):\n",
        "    with tf.name_scope(\"correct_prediction\"):\n",
        "        # 计算正确率,下面是一个布尔型列表\n",
        "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(prediction, 1))\n",
        "    with tf.name_scope(\"accuracy\"):\n",
        "        # 求准确率，首先把布尔类型转化为浮点类型\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        " \n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    # 保存Tensorboard文件\n",
        "    writer = tf.summary.FileWriter(\"logs/\", sess.graph)\n",
        "    for epoch in range(200):\n",
        "        \n",
        "        for batch in range(n_batch):\n",
        "            # 使用函数获取一个批次图片\n",
        "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "            sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
        "            \n",
        " \n",
        "        acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})\n",
        "\n",
        "        print(\"Iter \" + str(epoch) + \",Testing Accuracy \" + str(acc))\n",
        "        tbc.save_value(\"just a test\", \"line_name\", epoch,acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}